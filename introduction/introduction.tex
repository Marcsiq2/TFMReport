\normallinespacing

\chapter{Introduction}

\label{chap:introduction}
Music is a very important part of the life of most people. Depending on our mood or moment in the day or lives, music can be understood in very different ways. In some moments we understand music as a simple distraction, a soundtrack to our daily tasks without paying much attention to it. In other moments, when we consciously listen to music we can be very touched and excited by it. This engaging part of music is largely due to the human component added to the performance. Instead of reading a score, musicians play the music on their way, by changing (unconsciously or consciously if the performer wants to achieve a specific goal) a lot of "parameters" of it such as intensity, velocity, volume or articulation of each note. 

% The study of music expressive performance, from a computational point of view, consists of characterizing the  deviations that a musician, when performing a musical piece, introduces in the performance. In this work we are going to focus on modelling guitar scores and performances. In Section~\ref{sec:structure} we briefly explain how this thesis is organized.

Computational modelling of expressive music performance has been widely studied in the past. While previous work in this area has been mainly focused on classical piano music, there has been very little work on guitar music, and such work has focused on monophonic guitar playing. 

In this work, we present a machine learning approach to automatically generate expressive performances from non expressive music scores for polyphonic guitar. We treated guitar as an hexaphonic instrument, obtaining a polyphonic transcription of performed musical pieces. Features were extracted from the scores and performance actions were calculated from the deviations of the score and the performance. Machine learning techniques were used to train computational models to predict the aforementioned performance actions. Qualitative and quantitative evaluations of the models and the predicted pieces were performed. 


\section{Structure of the report}
\label{sec:structure}
In this chapter we discuss the motivation of this master's thesis, the main objectives and we explain briefly the structure of this report.
The rest of this thesis is organized as follows: in Chapter~\ref{chap:sota}, we present some related work in expressive music performance modelling specially focused on polyphonic music. In Chapter~\ref{chap:materials}, the materials used in this work are described. In Chapter~\ref{chap:methods}, we present the proposed methodology. In Chapter~\ref{chap:results}, the evaluation measures and results are presented. We conclude with a brief discussion and provide suggestions for future improvements in Chapter~\ref{chap:discussion}. 

In order to complement this thesis we present 3 Appendices: Appendix~\ref{app:dataset} documenting the dataset used for this work, Appendix~\ref{app:code} documenting the developed code and Appendix~\ref{app:survey} gathering all responses to the On-line Survey.

\section{Motivation}
\label{sec:motivation}
While most studies about guitar modelling are focused on monophonic performances, the aim of this master thesis is to investigate on the modelling of expressiveness in polyphonic (hexaphonic) guitar music. We will base our approach on previous studies by Giraldo~\cite{Giraldo2016} who computed expressive performance models for monophonic jazz guitar. Treating guitar as a monophonic instrument limits hardly the polyphonic nature of the instrument, but avoids the problems related to polyphonic music transcription. The main objective of this thesis will be to define a set of features extending previous work on monophonic guitar performances to polyphonic performances. Those features aim to represent the different nuances in time, duration or volume that the guitarist introduce when performing a musical piece, appearing both in the temporal or \textit{horizontal} axis (as a monophonic melody), but also should represent the \textit{vertical} axis representing the simultaneity between notes. The features should represent the variations in time and energy that the performer introduce, and those will depend on the context of the note if it is part of the melody or the harmonic accompaniment.

Understanding this little nuances that professional players perform when reading and performing a musical piece could help less trained musicians to improve their playing. This models could also be used by music annotation software in order to generate expressive performances from scores composed by users, and get a better idea on how the score would be performed by a professional guitar player instead a straight forward score to midi conversion.

%\todo[inline]{[NEW PARAGRAPH] expected results, possible future directions from the framework, and the data}

\section{Thesis statement}
In this section we present the main hypothesis of this master's thesis:

% \textit{Its possible to adapt and extend music expression analysis on monophonic guitar music to polyphonic guitar. Using information extracted about each note and its musical context and by training models by means of machine learning, we are able to predict little transformations in timing or energy. By synthesizing those artificially generated expressive music performances it would be hard for the listener to differentiate those from the synthesized real performance.}

\textit{It is possible to computationally capture and model the expressive nuances that a musician introduces when performing a musical piece, taking the polyphonic guitar as a study case.}


\section{Objectives}
The aim of this work is to study and predict computationally the little nuances or \textit{Performance Actions} that musicians do when performing a musical score, focusing on onset and energy deviations, taking the polyphonic (hexaphonic) guitar as a study case. This study will consider, as explained in section~\ref{sec:motivation}, both horizontal or melodic axis and vertical or harmonic axis.

The specific objectives are as follows:

\begin{itemize}[noitemsep]
\item To create a database of hexaphonic recordings played by a guitarist and their corresponding scores.
\item To automatically transcribe the audio of the hexaphonic recordings into a machine-readable format (MIDI).
\item To adapt existing code libraries to extract descriptors from the score which allow us to characterize the notes vertically and horizontally.
\item To create code libraries which allow us to align and compare the transcribed hexaphonic recordings to the score in order to extract performance actions.
\item To provide a few manually corrected performance to score alignments.
\item To generate different models that try to predict performance actions (onset deviation and energy ration) by using Machine Learning techniques.
\item To analyse which descriptors influence more the accuracy of these models, so to say, which descriptors represent more the behaviour of the musician.
\item To obtain not only quantitative machine learning results but also qualitative results by surveying different users.
\end{itemize}

\cleardoublepage

