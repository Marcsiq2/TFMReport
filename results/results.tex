\chapter{Results}
\label{chap:results}
In this chapter we are going to present the obtained results using the previous models, both from a quantitative point of view, by measuring correlation coefficient over predicted data and from a qualitative point of view, by surveying a few listeners with predicted and real performance synthesis. Firstly, in section~\ref{sec:features} we are going to apply feature selection in order to see what features are more relevant in order to obtain better prediction for performance actions. In section~\ref{sec:ev_measures} we are going to explain what measures are we going to consider for both results analysis. Finally in section~\ref{sec:ev_results} we present separately the results from both evalutaions.

\section{Feature Selection}
In figure~\ref{tab:feature_selection} we present the Correlation Coefficients (CC) between predicted and actual Performance Actions for Onset deviation and Energy Ratio. In red we show the accuracy for the whole Train dataset and in blue the results with 10 fold Cross-Validation. As we can see, for Cross-validation with just 5 features we achieve the best CC.

\input{Tables/feature_selection}
\input{Figures/feature_selection}



\label{sec:features}

\section{Evaluation Measures}
\label{sec:ev_measures}

\section{Evaluation Results}
\label{sec:ev_results}

\subsection{Quantitative evaluation}
In table~\ref{tab:results_ml_cv} we show the results comparing different Machine Learning algorithms both with cross-validation and with the whole Train dataset. We present CC for Energy ratio and onset deviation for the whole dataset, for just the best 5 features and also for the best subset of features. As we can see we achieve the best results with Decision Trees and also with just 5 features or the best subset we outperform the normal dataset.

\input{Tables/results_ml_cv}
\input{Tables/results_ml_tt}
\input{Tables/results_mixed}

\subsection{Qualitative evaluation}

For the qualitative survey, different MIDIs with the model's predictions are generated and then synthesized. We asked people to guess how "human" they were by comparing them with real performances through an on-line survey~\footnote{You can find the survey here: \url{https://marcsiq2.github.io/}}. We asked them to rate from 0 to 100 how "human" the audios where. Results from over 10 participants in figure~\ref{fig:survey} show that people find the score more "human" than the actual performance and predicted score. However, as we obtain very similar results for performance and prediction, we can say that our models predict very well the actual human performances. 

\begin{figure}
\caption{Results of the on-line survey with performance, predicted and straight score synthesized midis.}
\label{fig:survey}
\centering
\includegraphics[width=0.7\textwidth]{Figures/survey.pdf}
\end{figure}


\cleardoublepage

